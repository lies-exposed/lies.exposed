client_max_body_size 2G;

# Streaming endpoints need longer timeouts for LLM inference
# These timeouts apply to proxied requests (chat streaming, file uploads, etc.)
proxy_connect_timeout 30s;
proxy_send_timeout 300s;        # 5 minutes for sending request body
proxy_read_timeout 300s;        # 5 minutes for reading response
proxy_buffering off;            # Disable buffering for streaming responses
proxy_request_buffering off;    # Disable request buffering

# WebSocket support for real-time communication
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "upgrade";
proxy_set_header Connection "Upgrade";

# Keep-alive for long-running connections
keepalive_timeout 310s;