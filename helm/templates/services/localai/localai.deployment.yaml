apiVersion: apps/v1
kind: Deployment
metadata:
  name: localai
  namespace: {{ .Release.Namespace }}
  labels:
    lies.exposed/name: localai
    app.kubernetes.io/instance: {{ .Release.Name | quote }}
    app.kubernetes.io/namespace: {{ .Release.Namespace | quote }}
    app.kubernetes.io/component: ai
    app.kubernetes.io/managed-by: Helm

spec:
  replicas: 1
  selector:
    matchLabels:
      lies.exposed/name: localai
  template:
    metadata:
      labels:
        lies.exposed/name: localai
        app.kubernetes.io/instance: {{ .Release.Name | quote }}
        app.kubernetes.io/namespace: {{ .Release.Namespace | quote }}
        app.kubernetes.io/component: ai
    spec:
      containers:
        - name: localai
          envFrom:
          - configMapRef:
              name: localai-env
          # image: localai/localai:latest-aio-gpu-intel
          image: localai/localai:latest-aio-cpu
          livenessProbe:
            exec:
              command:
                - curl
                - -f
                - http://localhost:8080/readyz
            failureThreshold: 5
            periodSeconds: 60
            timeoutSeconds: 1200
          ports:
            - containerPort: 8080
              protocol: TCP
          tty: true
          volumeMounts:
            - name: localai-models-pv
              mountPath: /models
          resources:
            limits:
              memory: 6Gi
              cpu: "3"
            requests:
              memory: 4Gi
              cpu: "1"
      restartPolicy: Always
      volumes:
        - name: localai-models-pv
          persistentVolumeClaim:
            claimName: localai-models-pv-claim
