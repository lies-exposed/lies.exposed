apiVersion: apps/v1
kind: Deployment
metadata:
  name: localai
  namespace: {{ .Release.Namespace }}
{{ tuple . "localai" | include "localai.labels" | indent 2 }}

spec:
  replicas: 1
  selector:
    matchLabels:
      lies.exposed/name: localai
  template:
    metadata:
{{ tuple . "localai" | include "localai.labels" | indent 6 }}
    spec:
      containers:
        - name: localai
          envFrom:
          - configMapRef:
              name: localai-env
          # image: localai/localai:master-aio-gpu-intel
          # image: localai/localai:latest-aio-cpu
          image: localai/localai:master-aio-cpu
          # image: localai/localai:v3.3.2-aio-cpu
          imagePullPolicy: Always
          # livenessProbe:
          #   exec:
          #     command:
          #       - curl
          #       - -f
          #       - http://localhost:8080/readyz
          #   failureThreshold: 5
          #   periodSeconds: 60
          #   timeoutSeconds: 1200
          ports:
            - containerPort: 8080
              protocol: TCP
          tty: true
          volumeMounts:
            - name: localai-models-pv
              mountPath: /models
            - name: localai-backends-pv
              mountPath: /backends
          resources:
            limits:
              memory: 6Gi
              cpu: 3000m
            requests:
              memory: 4Gi
              cpu: 1000m
      restartPolicy: Always
      volumes:
        - name: localai-models-pv
          persistentVolumeClaim:
            claimName: localai-models-pv-claim
        - name: localai-backends-pv
          persistentVolumeClaim:
            claimName: localai-backends-pv-claim
